# Repositorio del Curso [Machine Learning de A a la Z: R y Python para Data Science](https://www.udemy.com/draft/2241862/?couponCode=GITHUB_PROMO_JB)
## Creado por [Kirill Eremenko](https://www.udemy.com/user/kirilleremenko/) y [Hadelin de Ponteves](https://www.udemy.com/user/hadelin-de-ponteves/)
## Traducido al español por [Juan Gabriel Gomila Salas](https://www.udemy.com/user/juangabriel2)


¿Estás interesado en conocer a fondo el mundo del Machine Learning? Entonces este curso está diseñado especialmente para ti!!

Este curso ha sido diseñado por Data Scientists profesionales para compartir nuestro conocimiento y ayudarte a aprender la teoría compleja, los algoritmos y librerías de programación de un modo fácil y sencillo.

En él te guiaremos paso a paso en el mundo del Machine Learning. Con cada clase desarrollarás nuevas habilidades y mejorarás tus conocimientos de este complicado y lucrativa sub rama del Data Science.

### Temario del curso

Este curso es divertido y ameno pero al mismo tiempo todo un reto pues tenemos mucho de Machine Learning por aprender. Lo hemos estructurado del siguiente modo:

- Parte 1 - Preprocesamiento de datos
- Parte 2 - Regresión: Regresión Lineal Simple, Regresión Lineal Múltiple, Regresión Polinomial, SVR, Regresión en Árboles de Decisión y Regresión con Bosques Aleatorios
- Parte 3 - Clasificación: Regresión Logística, K-NN, SVM, Kernel SVM, Naive Bayes, Clasificación con Árboles de Decisión y Clasificación con Bosques Aleatorios
- Parte 4 - Clustering: K-Means,  Clustering Jerárquico
- Parte 5 - Aprendizaje por Reglas de Asociación: Apriori, Eclat
- Parte 6 - Reinforcement Learning: Límite de Confianza Superior, Muestreo Thompson
- Parte 7 - Procesamiento Natural del Lenguaje: Modelo de Bag-of-words  y algoritmos de NLP
- Parte 8 - Deep Learning: Redes Neuronales Artificiales y Redes Neuronales Convolucionales
- Parte 9 - Reducción de la dimensión: ACP, LDA, Kernel ACP
- Parte 10 - Selección de Modelos & Boosting: k-fold Cross Validation, Ajuste de Parámetros, Grid Search, XGBoost

Además, el curso está repleto de ejercicios prácticos basados en ejemplos de la vida real, de modo que no solo aprenderás teoría, si no también pondrás en práctica tus propios modelos con ejemplos guiados.

Y como bonus, este curso incluye todo el código en Python y R para que lo descargues y uses en tus propios proyectos.

Puedes apuntarte al curso de Machine Learning con un descuento del 90% de su precio original [desde aquí](https://www.udemy.com/draft/2241862/?couponCode=GITHUB_PROMO_JB)

### Lo que aprenderás

- Dominar el Machine Learning con R y con Python.
- Tener intuición en la mayoría de modelos de Machine Learning.
- Hacer predicciones precisas y acertadas.
- Crear unos análisis elaborados.
- Crear modelos de Machine Learning robustos y consistentes.
- Crear valor añadido a tu propio negocio.
- Utilizar el Machine Learning para cuestiones personales.
- Dominar aspectos específicos como por ejemplo Reinforcement Learning, NLP o Deep Learning
- Conocer las técnicas más avanzadas como la reducción de la dimensionalidad.
- Saber qué modelo de Machine Learning usar para cada tipo de problema.
- Crear toda una librería de modelos de Machine Learning y saber cómo combinarlos para resolver cualquier problema.

### ¿Hay requisitos para seguir correctamente el curso?

- Con el nivel de matemáticas de secundaria y bachillerato es suficiente.

### ¿Para quién es este curso?

- Cualquier estudiante que esté interesado en el Machine Learning.
- Estudiantes con nivel de matemáticas de bachillerato que quieren iniciarse en Machine Learning.
- Estudiantes de nivel intermedio con conocimientos básicos de Machine Learning, incluyendo algoritmos clásicos de regresión lineal o logística, pero que quieren aprender más y explorar los diferentes campos del Machine Learning.
- Estudiantes que no se sienten cómodos programando pero se interesan por el Machine Learning y quieren aplicar las técnicas al análisis de data sets.
- Universitarios que quieren iniciarse en el mundo del Data Science.
- Cualquier analista de datos que quiera mejorar sus habilidades en Machine Learning.
- Personas que no están satisfechas con su trabajo y quieren convertirse en Data Scientist.
- Cualquier persona que quiera añadir valor a su empresa con el poder del Machine Learning.

### Pequeña Guía para crear nuevos Environments e instalarle paquetes usando Anaconda Prompt (solo para Windows)

Dando por hecha la instalación de Anaconda o Miniconda en su sistema operativo, y que se cuenta con alguna versión superior o igual a Python 3.6, siga los pasos:
1. Abra Anaconda Prompt desde la barra de búsqueda de Windows o desde el acceso directo creado en la carpeta de Anaconda.
2. En Anaconda Prompt podrá ver que al principio de cada entrada se lee <kbd>base</kbd>, lo cual indica que se está usando el ambiente predeterminado.
3. Para crear un ambiente nuevo use el comando <kbd>conda create -n "nombre-del-nuevo-envorinment" -y</kbd>, donde cada espacio debe ser reemplazdo por un guion.
4. Para activar su nuevo ambiente siga la nomenclatura <kbd>conda activate "nombre-del-nuevo-envorinment"</kbd>, en este paso se cambiará <kbd>base</kbd> por <kbd>"nombre-del-nuevo-envorinment"</kbd> por cada entrada en la consola.
5. Ahora, para instalar paquetes para su versión de Python, solo es necesario escribir el comando <kbd>conda install "nombre-del-paquete"</kbd>. Este comando puede variar según el paquete que se instale, es necesario leer la documentación sobre la instalación de cada paquete en su página oficial, o incluso en su reopsitorio de GitHub.
6. Para comprobar la correcta instalación de un paquete se escribe <kbd>python</kbd> para usar el intérprete de Python en la consola, posteriormente se importa la librería <kbd>import "librería"</kbd>, si el comando se ejecuta correctamente la instalación fue exitosa. Para revisar la versión del paquete se introduce el comando <kbd>"nombre-del-paquete".__version__</kbd> (nótese que se escriben dos guiones bajos antes y después de "version").
7. Si lo que se desea es actualizar alguna versión de un paquete se escribe <kbd>conda update "nombre-del-paquete"</kbd>

### Relevant GitHub Repositories

- [Statsmodels](https://github.com/statsmodels/statsmodels) es una biblioteca de Python 3.8, 3.9 y 3.10 que proporciona clases y funciones para la estimación de muchos modelos estadísticos diferentes, así como para realizar pruebas estadísticas y exploración de datos estadísticos. Para su instalación escriba <kbd>conda install -c conda-forge statsmodels</kbd> en Anaconda Prompt dentro del ambiente deseado.

### Solved Issues

Debido al continuo cambio de python, las actualizaciones de las librerías, dependencias, así como de anaconda, pueden existir ciertos problemas con los códigos y/o librerías. La lista de problemas se actualizará con el tiempo.
- Código fuente de "***Parte 1: Preprocesamiento de datos***" actualizado para Python 3.10.8:

~~~python
import numpy as np # For mathematical operations
import matplotlib.pyplot as plt # For plotting information
import pandas as pd # For managing large data collections

# Importing dataset from ML Datasets folder
dataset = pd.read_csv('Data.csv')
x = dataset.iloc[:, :-1].values
y = dataset.iloc[:, 3].values

# Unknown data (nan or NaN)
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(missing_values = np.nan, strategy = "mean")
imputer = imputer.fit(x[:, 1:3])
x[:, 1:3] = imputer.transform(x[:, 1:3])

# DATOS CATEGÓRICOS
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.compose import ColumnTransformer

labelencoder_x = LabelEncoder()
x[:, 0] = labelencoder_x.fit_transform(x[:, 0])

ct = ColumnTransformer(
    [('one_hot_encoder', OneHotEncoder(categories='auto'), [0])],   
    remainder='passthrough'                        
)
x = np.array(ct.fit_transform(x), dtype=np.float64)

labelencoder_y = LabelEncoder()
y = labelencoder_y.fit_transform(y)

# DIVIDIR el dataset en conjunto de entrenamiento y conjunto de testing
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)

# Escalado de variables
from sklearn.preprocessing import StandardScaler
sc_x = StandardScaler()
x_train = sc_x.fit_transform(x_train)
x_test = sc_x.transform(x_test)
~~~

- Creación de un Environment apropiado de Python con Anaconda para el IDE Spyder: [Spyder FAQ, Cómo instalar paquetes de Python y que el editor los reconozca](https://docs.spyder-ide.org/5/faq.html#using-packages-installer).
- Al crear el nuevo Environment para Spyder, se necesitaron instalar múltiples paquetes:
  - SciPy
  - NumPy
  - Pandas
  - Matplotlib
  - Sklearn
  - TensorFlow
  - Keras
  - PyTorch
  - Theano

  Se pueden encontrar tutoriales de descarga usando Anaconda Prompt en [anaconda.org](https://anaconda.org/). 
  <kbd>conda install 'package_name'</kbd>
  <kbd>conda activate spyder-env</kbd>
- Problema con el uso de la librería scikit-learn para Python 3.8 y Python 3.9 solucionado desde Anaconda Prompt: [Jezdez Solution](https://github.com/conda/conda/issues/11795#issuecomment-1335666474).
